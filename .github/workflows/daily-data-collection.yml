name: Daily Data Collection

on:
  schedule:
    - cron: '0 5 * * *' 
  workflow_dispatch:

jobs:
  collect-and-load-data:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-chromedriver
        sudo ln -s /usr/lib/chromium-browser/chromedriver /usr/bin/chromedriver
    
    - name: Run data collection and loading script
      env:
        AZURE_SQL_SERVER: ${{ secrets.AZURE_SQL_SERVER }}
        AZURE_SQL_DATABASE: ${{ secrets.AZURE_SQL_DATABASE }}
        AZURE_SQL_USER: ${{ secrets.AZURE_SQL_USER }}
        AZURE_SQL_PASSWORD: ${{ secrets.AZURE_SQL_PASSWORD }}
      run: |
        python web_scraping_voos_salvador.py
